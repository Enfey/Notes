> This house believes that AI should not be completely relied on for important decisions within the NHS and government.

# Opening Speeches
## Proposition
- To begin, must define 'completely relied on' = using AI systems as the final or sole decision-maker without any degree of human oversight.
- Define 'important decisions' = matters affecting lives, rights, health, and policy(patient treatment, resource allocation)
- Proposition stance: We postulate that AI can support decisions - but can never act as an authoritative stand-in for human judgement. 
- AI cannot understand human emotions, context, moral nuance. NHS and gov decisions often require compassions, ethics, values, not just historical data. For example, deciding who receives end-of-life care.
- AI learns from historical data, if data is biased, so are its decisions, biased training data harm minorities/underrepresented groups, can lead to deadly outcomes. 
- AI decisions can be opaque. Who do we blame if the AI makes a harmful decision, the programmer, the machine, or the minister?Human oversight ensures reliable accountability, for this reason we believe it should only assist, and never decide. 
- AI should assist professionals by analysing data, not replacing them; people are more than numbers, reducing them to mathematical problems without insertion of moral grounding is inhumane and could have real cost. 

## Opposition
- The motion assumes AI replaces humans, but in practice, AI enhances human capacity.
- 'completely relied on' doesn't mean blindly trusted, it means systems built on consistent data-driven logic. 
- AI can, and sometimes should, be fully relied upon for importance decisions, as it can be fairer, faster, and sometimes more accurate than human counterparts.
- Humans make emotional, inconsistent, and biased decisions. AI can process massive datasets objectively, reducing bias, and improving decision making consistency. e.g., medical image recognition can detect cancers more accurately than some doctors
- The NHS is overwhelmed, offloading decision making to systems that can handle data faster than humans results in faster time to diagnose and discharge, providing much needed help in the current medical landscape. 
- AI bases decisions on evidence, not politics, fatigue, or emotion. In gov, data-led decisions can improve fairness. For example, benefits distribution can be improved. May posit that this is ruthless, the opposition argues that that the distribution will be at least consistent with the intention of policymakers, rather than consistent with individual benefit case managers mood and personal feelings. 
- The goal is better decisions, not clinging to human flaws and marking them as ethical superiority - there is a need for accelerated processes in NHS and gov for this country to thrive, and AI taking the lead on important decisions is a step in the right direction. 

# Rebuttal
## Proposition
- "AI is more objective" - untrue, reflect biased data, and human-coded priorities, morally unjust, as proprietary systems, users will never see the data that is used to make decisions affecting them. ACM 2.7 'Foster public awareness and understanding of computing, related technologies, and their consequences. ' Mandates that this is the case, but the degree of transparency would have to be huge if such an important system were to ever steward important decisions, in theory. 
- "Humans make errors" - humans can improve, and this is an individual process; AI errors scale across systems and affect thousands instantly, we cannot turn back the clock when catastrophic failures occur. 
- "AI is efficient" - sure, but efficiency without safeguarding causes harm faster. Harm in sensitive areas such as these is not easily reversed. 

## Opposition
- AI "lacks empathy" - empathy is emotional, not rational. Medicine and policy must rely on evidence, not emotion. To do so is to abide the professional mandate ACM 1.1 'Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing.'
- AI is biased - Bias can be identified and fixed; human bias often cannot be easily identified and fixed, as it is dispersed across thousands of individuals. To have bias in the final say 'just because AI has no morals' is to fail stakeholders to the utmost degree. 
- AI lacks accountability - responsibility still lies with the organisation deploying it, as with any human system. The constraints of the system are according to the will of the deployer, as such the actions taken by the AI are usually direct result of the intentions of the deployer, thus the blame lies with those who have control.

# Closing
## Proposition
- Important decisions shape life and society, require conscience, compassion, and accountability; all things provided by a human.
- AI is just a tool, and should never be used in place of an autonomous, ethically constrained human. 
- Let AI inform human judgement, not replace it. 

## Opposition
- AI doesn't replace morality - it actually accentuates it by enforcing consistency and providing supporting evidence for outcomes in crucial decisions. 
- With proper oversight, training, and transparency, reliance on AI improves outcomes.
- The future of public service should be smart, efficient and data driven; the use of well-designed AI to steward decisions is a step toward a better Britain. 
