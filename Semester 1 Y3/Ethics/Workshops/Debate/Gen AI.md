> This house believes that negative outcomes from the use of generative AI are the responsibility of the user not the creator.

# Opening Speeches (pro, opp, 4 min)
## Proposition
- Generative AI = type of AI that creates new content such as text and images, by learning patterns from existing large corpora. Users able to produce creative output via handcrafted prompts.
- Negative outcomes = harms from usage; misinformation, plagiarism, bias, deepfakes, exploitation. 
- We must ask: who is responsible when harm occurs - the creator or the user?
- Proposition asserts the following stance: AI developers provide tools; users decide how to use them. Responsibility lies with the user.
- Historically, technology has been morally neutral; responsibility arises from human action, a hammer was designed to build houses, not be a murder weapon; the blame has always lied with the wielder. Gen AI is merely advanced technology, its nature remains the same.
- AI doesn't act independently follows user prompts, thus reflecting user intention, not creator design, though the design has a degree of influence. Responsibility follows from agency.
- Thus, creators should ensure safe design and transparency, introducing guardrails where possible, but accountability of misuse ultimately rests with user's actions. 
## Opposition
- We postulate that this motion ignores the power imbalance between creators and users
- Gen AI is not a meek tool - it is a complex interconnected system that can produce harmful outputs *on its own* due to creator design. 
- Therefore, creators share or bear the primary responsibility for negative outcomes. 
- Creators are those that design system; each model reflects choices in data sources, training methods, guardrails. If outputs are harmful without misguided user intention, who is to blame? Pure design failure, users cannot foresee such embedded problems. 
- Developers are intelligent enough to know that AI can generate misinformation etc, if risks are predictable, do creators not have an ethical duty to mitigate them?
- AI companies profit massively from widespread use, they must accept the corresponding responsibility of disseminating a product which has the potential to cause widespread unintended harm. 
- Harms like bias and disinformation are systemic, not individual. Responsibility is therefore systemic, starting with the creators. 
- Thus true accountability starts at the source, those who design and release the technology. 


# Rebuttal (pro, opp, 3 min)
## Proposition
- "Creators foresee harm and must prevent it" - nigh on impossible to anticipate all misuse. Jailbreaks etc, users adapt even with guardrails.
- "AI creators embed bias" - bias is a design issue, but using AI harmfully is inherently a user choice, users control inputs and purpose, and thus control the distribution of outputs. 
- Like social media users spreading lies - platform creators canâ€™t monitor every post in real time; even if they could, the definition of "misuse" may not be so clear cut. Often case by case, it may not be up to AI developers to determine misuse, definition may need be designated by a higher authority. 
## Opposition
- "Innovation will stop" - safety and accountability will improve innovation, not kill it
- "Bias is a design issue" - while true, this leads to harmful user outcomes regardless of agency, ACM 2.5 mandates professionals 'Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis of possible risks'. By injecting bias either unintentionally or intentionally, professional betray their allegiance to serving the greater good. 
- It doesn't take a considerable amount of effort to identify misuse vs intended use. Such things are planned when designing such a system. In a proper development lifecycle for a sensitive system, guardrails should always be introduced, even if misuse is not anticipated, as the degree of dissemination of such technology can never be predicted, one must try and combat all harms possible. To not do so is to merely shift responsibility out of laziness. 

# Closing(pro, opp, 2 min)
## Proposition
- Creators can build safeguards, but cannot control free choice, or risk imposing limitations on those with good intentions. 
- To enforce responsibility without agency is unjust; agency lies with the user. 
- To promote innovation and fairness, we ask that you vote for the proposition. 
## Oppositions
- Users can only act within systems creators build; they cannot be blamed for flaws they didn't design. 
- Creators have the foresight, power, and moral duty(see deontological ethics) to prevent predictable harm. 
- Responsibility follows degree of control. 